{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b02380a-2cc2-403b-9041-d470b8739af2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, expr, sum, split, trim, lower, col, input_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e067488c-b478-4856-95b9-30cec7f5de66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Bronze():\n",
    "  def __init__(self):\n",
    "    self.base_data_dir = \"/FileStore/test\"\n",
    "\n",
    "  def getSchema(self):\n",
    "    return '''InvoiceNumber string, CreatedTime bigint, StoreID string, PosID string, CashierID string,\n",
    "            CustomerType string, CustomerCardNo string, TotalAmount double, NumberOfItems bigint, \n",
    "            PaymentMethod string, TaxableAmount double, CGST double, SGST double, CESS double, \n",
    "            DeliveryType string,\n",
    "            DeliveryAddress struct<AddressLine string, City string, ContactNumber string, PinCode string, State string>,\n",
    "            InvoiceLineItems array<struct<ItemCode string, ItemDescription string, ItemPrice double, ItemQty bigint, TotalValue double>>'''\n",
    "\n",
    "  def readInvoices(self):\n",
    "    return ( spark.readStream\n",
    "            .format(\"json\")\n",
    "            .schema(self.getSchema())\n",
    "            .load(f\"{self.base_data_dir}/data/invoices\")\n",
    "            .withColumn(\"InputFile\", input_file_name())\n",
    "          )\n",
    "\n",
    "  def process(self):\n",
    "    print(\"Starting Bronze Stream ...\")\n",
    "    invoicesDF = self.readInvoices()\n",
    "    sQuery = ( invoicesDF.writeStream\n",
    "              .queryName(\"bronze-ingestion\")\n",
    "              .format(\"delta\")\n",
    "              .option(\"checkpointLocation\", f\"{self.base_data_dir}/checkpoint/invoices_bz\")\n",
    "              .outputMode(\"append\")\n",
    "              .toTable(\"invoices_bz\")\n",
    "            )\n",
    "    print(\"Done\\n\")\n",
    "    return sQuery\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21c337fd-3d47-4e56-a50e-d48808041cde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Gold():\n",
    "  def __init__(self):\n",
    "    self.base_data_dir = \"/FileStore/test\"\n",
    "  \n",
    "  def readBronze(self):\n",
    "    return spark.readStream.table(\"invoices_bz\")\n",
    "  \n",
    "  def getAggregates(self, temp_df):\n",
    "    return ( temp_df.groupBy(\"CustomerCardNo\")\n",
    "            .agg(sum(\"TotalAmount\").alias(\"TotalAmount\"),\n",
    "                 sum(expr(\"TotalAmount*0.02\")).alias(\"TotalPoints\"))\n",
    "            )\n",
    "\n",
    "  def saveResults(self, results_df):\n",
    "    return ( results_df.writeStream\n",
    "            .queryName(\"gold-processing\")\n",
    "            .format(\"delta\")\n",
    "            .option(\"checkpointLocation\", f\"{self.base_data_dir}/checkpoint/customer_rewards\")\n",
    "            .outputMode(\"complete\")\n",
    "            .toTable(\"customer_rewards\")\n",
    "          )\n",
    "    \n",
    "  def process(self):\n",
    "    print(\"Starting Gold Stream ...\")\n",
    "    invoices_df = self.readBronze()\n",
    "    aggregate_df = self.getAggregates(invoices_df)\n",
    "    sQuery = self.saveResults(aggregate_df)\n",
    "    return sQuery\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Streaming-Aggregates",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}