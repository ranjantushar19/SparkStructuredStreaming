{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c04b04f-b5c8-41b5-ac34-3fc92224f305",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, from_json, window, sum, to_timestamp, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77b7c31a-d514-4c63-af1c-6721ce8eeca1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class TradeSummary:\n",
    "  def __init__(self):\n",
    "    self.base_data_dir = \"/FileStore/test\"\n",
    "\n",
    "  def getSchema(self):\n",
    "    return StructType([\n",
    "      StructField(\"CreatedTime\", StringType()),\n",
    "      StructField(\"Type\", StringType()),\n",
    "      StructField(\"Amount\", IntegerType()),\n",
    "      StructField(\"BrokerCode\", StringType()),\n",
    "    ])\n",
    "\n",
    "  def readBronze(self):\n",
    "    return spark.readStream.table(\"kafka_bz\")\n",
    "\n",
    "  def getTrade(self, kafka_df):\n",
    "    return (kafka_df.select(from_json(kafka_df.value, self.getSchema()).alias(\"value\"))\n",
    "            .select(\"value.*\")\n",
    "            .withColumn(\"CreatedTime\", expr(\"to_timestamp(CreatedTime, 'yyyy-MM-dd HH:mm:ss')\"))\n",
    "            .withColumn(\"Buy\", expr(\"CASE WHEN Type == 'BUY' THEN Amount ELSE 0 END\"))\n",
    "            .withColumn(\"Sell\", expr(\"CASE WHEN Type == 'SELL' THEN Amount ELSE 0 END\"))\n",
    "    )\n",
    "\n",
    "  def getAggregate(self, trade_df):\n",
    "    return ( trade_df.groupBy(window(trade_df.CreatedTime, \"15 minutes\"))\n",
    "            .agg(sum(\"Buy\").alias(\"TotalBuy\"),\n",
    "                 sum(\"Sell\").alias(\"TotalSell\")\n",
    "                 )\n",
    "            .select(\"window.start\", \"window.end\", \"TotalBuy\", \"TotalSell\")\n",
    "            )\n",
    "\n",
    "  def saveResults(self, results_df):\n",
    "    return ( results_df.writeStream\n",
    "            .queryName(\"trade-summary\")\n",
    "            .format(\"delta\")\n",
    "            .option(\"checkpointLocation\", f\"{self.base_data_dir}/checkpoint/trade_summary\")\n",
    "            .outputMode(\"complete\")\n",
    "            .toTable(\"trade_summary\")\n",
    "          )\n",
    "\n",
    "  def process(self):\n",
    "    kafka_df = self.readBronze()\n",
    "    trade_df = self.getTrade(kafka_df)\n",
    "    result_df = self.getAggregate(trade_df)\n",
    "    sQuery = self.saveResults(result_df)\n",
    "    return sQuery\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Tumbling-Window",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}